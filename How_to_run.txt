HOW TO RUN:

Clone this repo: git clone https://github.com/hrishabhkothary/Stock-Investment-Transaction-Analysis-and-Portfolio-Risk-Monitoring-System.git
The final Project tree should look like:

StockInvestmentProject/
│
├── txtfiles
    │
    ├── details_db_config.txt
    ├── details_psuedo_realtime.txt
├── db_config.py
├── create_tables.sql
├── generate_dummy_data.py
├── transactions.csv
├── constants.py
├── seed_investors.py
├── load_transactions.py
├── update_portfolio.py
├── analyze.py
├── master_etl.py
├── psuedo_realtime.py
├── requirements.txt
├── .gitignore
└── README.md

1. Install Python packages(Terminal):

  'pip install -r requirements.txt'

2. Setup MySQL DB: Open terminal:

  'mysql -u root -p < create_tables.sql'

  This: Creates your stock_investments DB Creates tables: investors, transactions, portfolios.

3. Add a dummy CSV (one time)

   Make sure transactions.csv exists(already existing in folder).

   OR Run,

  'python generate_dummy_data.py'

   This will create a big file (transactions.csv with 10,000+ rows).

4. Seed Investors:
   
    Run,
   
   'seed_investors.py'

   This: Connects to your stock_investments DB

         Inserts 5 dummy investors if they don’t exist

         Uses INSERT IGNORE so it won’t fail if they’re already there

         Prints a success message

         If seed_investors.py doesn’t work:

         In sql

          -- Run manually to verify:
             INSERT IGNORE INTO investors (investor_id, name) VALUES
             (1001, 'Investor 1001'),
             (1002, 'Investor 1002'),
             (1003, 'Investor 1003'),
             (1004, 'Investor 1004'),
             (1005, 'Investor 1005');

             ✅ Now run SELECT * FROM investors; — confirm!

             🟢 Key Rule
             Foreign Key means:
             ✅ transactions.investor_id must match investors.investor_id or insert fails.

             So:

             If you generate new IDs — adjust both seed_investors.py AND generate_dummy_data.py

5. Load transactions into DB:

   Run,

   'python load_transactions.py'

6. Update portfolios:

   Run,

   'python update_portfolio.py'

    This: Runs a JOIN & subquery. Calculates total quantity, average buy price, risk score. Stores it in portfolios.

7. Analyze and Visualize:

   Run,

  'python analyze.py'

   This: Pulls portfolios data. Plots a bar chart with seaborn. Opens a window so you see who owns what stocks.

8. Else Run:

   master_etl.py

   This runs all the scripts at a time.


✅ Perfect run order:

python generate_dummy_data.py

python seed_investors.py

python load_transactions.py

python update_portfolio.py

python analyze.py

✅ OR:


Run the entire ETL Pipeline


python master_etl.py


✅Batch Mode:

In Batch Mode, you run the ETL automatically at intervals (like hourly).

How to do it?

1. Open terminal:

Run,

crontab -e

2️. Add:

0 * * * * /usr/bin/python3 /path/to/StockInvestmentProject/load_transactions.py (# Run loader every hour)

5 * * * * /usr/bin/python3 /path/to/StockInvestmentProject/update_portfolio.py (# Run updater every hour, 5 mins later)

This:

Loads new transactions hourly. Updates portfolios hourly.

✅Real-Time Mode  - Batch means “process all at once, on schedule”. Real-time means “process each new trade immediately”.

A simple version for real-time:

-Use watchdog (a Python library) to monitor a folder for a new CSV.

-Or connect to a message broker (Kafka, RabbitMQ, etc).

Example simple loop:

#pseudo-realtime.py

import time
import os
while True:

if os.path.exists("transactions.csv"):
    os.system("python load_transactions.py")
    os.system("python update_portfolio.py")
time.sleep(10)  # check every 10 sec



OR for Kafka-style:

 -Send each new trade as a message.

 -Have a Python consumer that runs update_portfolio.py instantly.
